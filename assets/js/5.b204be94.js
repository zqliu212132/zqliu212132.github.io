(window.webpackJsonp=window.webpackJsonp||[]).push([[5],{10:function(i,n){var e=i.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=e)},106:function(i){i.exports=JSON.parse('{"":{"title":"","author":"","booktitle":"","image":"","year":202,"tags":[""],"badge":"","showhome":false,"highlight":false,"abstract":"","bibtex":"","url":"","code":"","website":"","video":"","supplementary":""},"chen2023class":{"title":"Class-Level Confidence Based 3D Semi-Supervised Learning","author":"Zhimin Chen, Longlong Jing, Liang Yang, <b>Yingwei Li</b>, and Bing Li","booktitle":"WACV, 2023","image":"/publications/chen2023class.jpg","year":2023,"tags":["3D perception"],"showhome":false,"highlight":false,"url":"https://arxiv.org/pdf/2210.10138.pdf","bibtex":"@article{chen2022class,</br>  title={Class-Level Confidence Based 3D Semi-Supervised Learning},</br>  author={Chen, Zhimin and Jing, Longlong and Yang, Liang and Li, Bing},</br>  journal={arXiv preprint arXiv:2210.10138},</br>  year={2022}</br>}"},"liu2022harnessing":{"title":"Harnessing Perceptual Adversarial Patches for Crowd Counting","author":"Shunchang Liu*, Jiakai Wang*, Aishan Liu, <b>Yingwei Li</b>, Yijie Gao, Xianglong Liu, Dacheng Tao","booktitle":"ACM CCS, 2022","image":"/publications/liu2022harnessing.jpg","year":2022,"tags":["Robustness"],"showhome":false,"highlight":false,"url":"https://dl.acm.org/doi/pdf/10.1145/3548606.3560566","code":"https://github.com/shunchang-liu/PAP-Pytorch","bibtex":"@inproceedings{liu2022harnessing,</br>  title={Harnessing Perceptual Adversarial Patches for Crowd Counting},</br>  author={Liu, Shunchang and Wang, Jiakai and Liu, Aishan and Li, Yingwei and Gao, Yijie and Liu, Xianglong and Tao, Dacheng},</br>  booktitle={Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},</br>  pages={2055--2069},</br>  year={2022}</br>}"},"guo2022context":{"title":"Context Enhanced Stereo Transformer","author":"Weiyu Guo, Zhaoshuo Li, Yongkui Yang, Zheng Wang, Russ Taylor, Mathias Unberath, Alan Yuille, <b>Yingwei Li</b>","booktitle":"ECCV, 2022","image":"/publications/guo2022context.png","year":2022,"showhome":true,"tags":["3D perception","Robustness"],"bibtex":"@inproceedings{guo2022context,</br>title={Context Enhanced Stereo Transformer},</br>author={Guo, Weiyu and Li, Zhaoshuo and Yang, Yongkui and Wang, Zheng and Taylor, Russ and Unberath, Mathias and Yuille, Alan and Li, Yingwei},</br>booktitle={ECCV},</br>year={2022}</br>}","url":"https://arxiv.org/pdf/2210.11719.pdf","code":"https://github.com/guoweiyu/Context-Enhanced-Stereo-Transformer"},"li2022lidarcamera":{"title":"DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection","author":"<b>Yingwei Li</b>, Adams Yu, Tianjian Meng, Ben Caine, Jiquan Ngiam, Daiyi Peng, Junyang Shen, Bo Wu, Yifeng Lu, Denny Zhou, Quoc Le, Alan Yuille, Mingxing Tan","booktitle":"CVPR, 2022","image":"/publications/li2022lidarcamera.jpg","year":2022,"highlight":true,"showhome":true,"tags":["3D perception","MultiModality","Robustness"],"bibtex":"@article{li2022deepfusion,</br>title={DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection},</br>author={Li, Yingwei and Yu, Adams Wei and Meng, Tianjian and Caine, Ben and Ngiam, Jiquan and Peng, Daiyi and Shen, Junyang and Wu, Bo and Lu, Yifeng and Zhou, Denny and others},</br>journal={arXiv preprint arXiv:2203.08195},</br>year={2022}</br>}","url":"https://arxiv.org/pdf/2203.08195.pdf","code":"https://github.com/tensorflow/lingvo","website":"https://ai.googleblog.com/2022/04/lidar-camera-deep-fusion-for-multi.html"},"xiao2022learning":{"title":"Learning from Temporal Gradient for Semi-supervised Action Recognition","author":"Junfei Xiao, Longlong Jing, Lin Zhang, Ju He, Qi She, Zongwei Zhou, Alan Yuille, <b>Yingwei Li</b>","booktitle":"CVPR, 2022","image":"/publications/xiao2022learning.jpg","year":2022,"showhome":true,"tags":["MultiModality"],"bibtex":"@article{xiao2021learning,</br>title={Learning from Temporal Gradient for Semi-supervised Action Recognition},</br>author={Xiao, Junfei and Jing, Longlong and Zhang, Lin and He, Ju and She, Qi and Zhou, Zongwei and Yuille, Alan and Li, Yingwei},</br>journal={arXiv preprint arXiv:2111.13241},</br>year={2021}</br>}","url":"https://arxiv.org/pdf/2111.13241.pdf","code":"https://github.com/lambert-x/video-semisup"},"gupta2022swapmix":{"title":"SwapMix: Diagnosing and Regularizing the Over-reliance on Visual Context in Visual Question Answering","author":"Vipul Gupta, Zhuowan Li, Adam Kortylewski, Chenyu Zhang, <b>Yingwei Li</b>, Alan Yuille","booktitle":"CVPR, 2022","image":"/publications/gupta2022swapmix.png","year":2022,"tags":["Robustness"],"bibtex":"@article{gupta2022swapmix,</br>title={SwapMix: Diagnosing and Regularizing the Over-Reliance on Visual Context in Visual Question Answering},</br>author={Gupta, Vipul and Li, Zhuowan and Kortylewski, Adam and Zhang, Chenyu and Li, Yingwei and Yuille, Alan},</br>journal={arXiv preprint arXiv:2204.02285},</br>year={2022}</br>}","url":"https://arxiv.org/pdf/2204.02285.pdf"},"jing2022depth":{"title":"Depth Estimation Matters Most: Improving Per-Object Depth Estimation for Monocular 3D Detection and Tracking","author":"Longlong Jing, Ruichi Yu, Jiyang Gao, Henrik Kretzschmar, Kang Li, Charles R. Qi, Hang Zhao, Alper Ayvaci, Xu Chen, Dillon Cower, <b>Yingwei Li</b>, Yurong You, Han Deng, Congcong Li, Dragomir Anguelov","booktitle":"ICRA, 2022","tags":["3D perception"],"image":"/publications/jing2022depth.jpg","year":2022},"li2022r4d":{"title":"R4D: Utilizing Reference Objects for Long-Range Distance Estimation","author":"<b>Yingwei Li</b>, Tiffany Chen, Maya Kabkab, Ruichi Yu, Longlong Jing, Yurong You, Hang Zhao","booktitle":"ICLR, 2022","image":"/publications/li2022r4d.jpg","year":2022,"tags":["3D perception","Robustness"],"showhome":true,"highlight":true,"bibtex":"@inproceedings{li2021r4d,</br>title={R4D: Utilizing Reference Objects for Long-Range Distance Estimation},</br>author={Li, Yingwei and Chen, Tiffany and Kabkab, Maya and Yu, Ruichi and Jing, Longlong and You, Yurong and Zhao, Hang},</br>booktitle={International Conference on Learning Representations},</br>year={2021}</br>}","url":"https://openreview.net/pdf?id=MQ2sAGunyBP","supplementary":"https://yingwei.li/data/iclr22-r4d-supp.pdf"},"mei2022fast":{"title":"Fast AdvProp","author":"Jieru Mei, Yucheng Han, Yutong Bai, Yixiao Zhang, <b>Yingwei Li</b>, Xianhang Li, Alan Yuille, Cihang Xie","booktitle":"ICLR, 2022","image":"/publications/mei2022fast.jpg","year":2022,"tags":["Robustness"],"bibtex":"@inproceedings{mei2021fast,</br>title={Fast AdvProp},</br>author={Mei, Jieru and Han, Yucheng and Bai, Yutong and Zhang, Yixiao and Li, Yingwei and Li, Xianhang and Yuille, Alan and Xie, Cihang},</br>booktitle={International Conference on Learning Representations},</br>year={2021}</br>}","url":"https://openreview.net/pdf?id=hcoswsDHNAW"},"pi2021searching":{"title":"Searching for TrioNet: Combining Convolution with Local and Global Self-Attention","author":"Huaijin Pi, Huiyu Wang, <b>Yingwei Li</b>, Zizhang Li, Alan Yuille","booktitle":"BMVC, 2021","image":"/publications/pi2021searching.jpg","year":2021,"tags":["AutoML"],"bibtex":"@article{pi2021searching,</br>title={Searching for TrioNet: Combining Convolution with Local and Global Self-Attention},</br>author={Pi, Huaijin and Wang, Huiyu and Li, Yingwei and Li, Zizhang and Yuille, Alan},</br>journal={arXiv preprint arXiv:2111.07547},</br>year={2021}</br>}","url":"https://www.bmvc2021-virtualconference.com/assets/papers/0345.pdf","code":"https://github.com/phj128/TrioNet"},"li2020shapetexture":{"title":"Shape-Texture Debiased Neural Network Training","author":"<b>Yingwei Li</b>, Qihang Yu, Mingxing Tan, Jieru Mei, Peng Tang, Wei Shen, Alan Yuille, Cihang Xie","booktitle":"ICLR, 2021","image":"/publications/li2020shapetexture.jpg","year":2021,"tags":["Robustness"],"showhome":true,"highlight":true,"bibtex":"@article{li2020shape,</br>title={Shape-texture debiased neural network training},</br>author={Li, Yingwei and Yu, Qihang and Tan, Mingxing and Mei, Jieru and Tang, Peng and Shen, Wei and Yuille, Alan and Xie, Cihang},</br>journal={arXiv preprint arXiv:2010.05981},</br>year={2020}</br>}","url":"https://arxiv.org/pdf/2010.05981.pdf","code":"https://github.com/LiYingwei/ShapeTextureDebiasedTraining","website":"https://iclr.cc/media/iclr-2021/Slides/2870.pdf","video":"https://slideslive.com/38953458/shapetexture-debiased-neural-network-training"},"yu2020cakes":{"title":"CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Network","author":"Qihang Yu, <b>Yingwei Li</b>, Jieru Mei, Yuyin Zhou, Alan Yuille","booktitle":"AAAI, 2021","image":"/publications/yu2020cakes.png","year":2021,"tags":["AutoML"],"bibtex":"@article{yu2020cakes,</br>title={Cakes: Channel-wise automatic kernel shrinking for efficient 3d network},</br>author={Yu, Qihang and Li, Yingwei and Mei, Jieru and Zhou, Yuyin and Yuille, Alan L},</br>journal={arXiv preprint arXiv:2003.12798},</br>volume={2},</br>year={2020}</br>}","url":"https://arxiv.org/pdf/2003.12798.pdf","code":"https://github.com/yucornetto/CAKES"},"bai2019adversarial":{"title":"Adversarial Metric Attack and Defense for Person Re-identification","author":"Song Bai, <b>Yingwei Li</b>, Yuyin Zhou, Qizhu Li, Philip H.S. Torr","booktitle":"TPAMI, 2020","image":"/publications/bai2019adversarial.png","year":2020,"tags":["Robustness"],"bibtex":"@article{bai2020adversarial,</br>title={Adversarial metric attack and defense for person re-identification},</br>author={Bai, Song and Li, Yingwei and Zhou, Yuyin and Li, Qizhu and Torr, Philip HS},</br>journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},</br>volume={43},</br>number={6},</br>pages={2119--2126},</br>year={2020},</br>publisher={IEEE}</br>}","url":"https://arxiv.org/pdf/1901.10650.pdf","code":"https://github.com/SongBaiHust/Adversarial_Metric_Attack"},"li2019regional":{"title":"Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations Against Defenses","author":"<b>Yingwei Li</b>, Song Bai, Cihang Xie, Zhenyu Liao, Xiaohui Shen, Alan Yuille","booktitle":"ECCV, 2020","image":"/publications/li2019regional.jpg","year":2020,"tags":["Robustness"],"showhome":true,"bibtex":"@inproceedings{li2020regional,</br>title={Regional homogeneity: Towards learning transferable universal adversarial perturbations against defenses},</br>author={Li, Yingwei and Bai, Song and Xie, Cihang and Liao, Zhenyu and Shen, Xiaohui and Yuille, Alan},</br>booktitle={European Conference on Computer Vision},</br>pages={795--813},</br>year={2020},</br>organization={Springer}</br>}","url":"https://arxiv.org/pdf/1904.00979.pdf","code":"https://github.com/LiYingwei/Regional-Homogeneity"},"li2020neural":{"title":"Neural Architecture Search for Lightweight Non-Local Networks","author":"<b>Yingwei Li</b>, Xiaojie Jin, Jieru Mei, Xiaochen Lian, Linjie Yang, Cihang Xie, Qihang Yu, Yuyin Zhou, Song Bai, Alan Yuille","booktitle":"CVPR, 2020","image":"/publications/li2020neural.png","year":2020,"tags":["AutoML"],"showhome":true,"highlight":true,"bibtex":"@inproceedings{li2020neural,</br>title={Neural architecture search for lightweight non-local networks},</br>author={Li, Yingwei and Jin, Xiaojie and Mei, Jieru and Lian, Xiaochen and Yang, Linjie and Xie, Cihang and Yu, Qihang and Zhou, Yuyin and Bai, Song and Yuille, Alan L},</br>booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},</br>pages={10297--10306},</br>year={2020}</br>}","url":"https://arxiv.org/pdf/2004.01961.pdf","code":"https://github.com/LiYingwei/AutoNL"},"mei2020atomnas":{"title":"AtomNAS: Fine-Grained End-to-End Neural Architecture Search","author":"Jieru Mei, <b>Yingwei Li</b>, Xiaochen Lian, Xiaojie Jin, Linjie Yang, Alan Yuille, Jianchao Yang","booktitle":"ICLR, 2020","image":"/publications/mei2020atomnas.png","year":2020,"tags":["AutoML"],"bibtex":"@article{mei2019atomnas,</br>title={Atomnas: Fine-grained end-to-end neural architecture search},</br>author={Mei, Jieru and Li, Yingwei and Lian, Xiaochen and Jin, Xiaojie and Yang, Linjie and Yuille, Alan and Yang, Jianchao},</br>journal={arXiv preprint arXiv:1912.09640},</br>year={2019}</br>}","url":"https://arxiv.org/pdf/1912.09640.pdf","code":"https://github.com/meijieru/AtomNAS"},"li2020learning":{"title":"Learning Transferable Adversarial Examples via Ghost Networks","author":"<b>Yingwei Li</b>, Song Bai, Yuyin Zhou, Cihang Xie, Zhishuai Zhang, Alan Yuille","booktitle":"AAAI, 2020</br>CVPR Workshop <b>(Oral)</b>, 2019","image":"/publications/li2020learning.jpg","year":2020,"tags":["Robustness"],"showhome":true,"bibtex":"@inproceedings{li2020learning,</br>title={Learning Transferable Adversarial Examples via Ghost Networks},</br>author={Li, Yingwei and Bai, Song and Zhou, Yuyin and Xie, Cihang and Zhang, Zhishuai and Yuille, Alan},</br>booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},</br>volume={34},</br>year={2020}</br>}","url":"https://arxiv.org/pdf/1812.03413.pdf","code":"https://github.com/LiYingwei/ghost-network"},"li2019volumetric":{"title":"Volumetric Medical Image Segmentation: A 3D Deep Coarse-to-Fine Framework and Its Adversarial Examples","author":"<b>Yingwei Li</b>*, Zhuotun Zhu* Yuyin Zhou, Yingda Xia, Wei Shen, Elliot K Fishman, Alan Yuille","booktitle":"Book Chapter: Deep Learning and CNN for Medical Image Computing , 2019","image":"/publications/li2019volumetric.jpg","year":2019,"tags":["Robustness"],"showhome":true,"bibtex":"@Inbook{Li2019,</br>author=\'Li, Yingwei and Zhu, Zhuotun and Zhou, Yuyin and Xia, Yingda and Shen, Wei and Fishman, Elliot K. and Yuille, Alan L.\',</br>title=\'Volumetric Medical Image Segmentation: A 3D Deep Coarse-to-Fine Framework and Its Adversarial Examples\',</br>bookTitle=\'Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\',</br>year=\'2019\',</br>publisher=\'Springer International Publishing\',</br>address=\'Cham\',</br>pages=\'69--91\',</br>isbn=\'978-3-030-13969-8\',</br>doi=\'10.1007/978-3-030-13969-8_4\',</br>url=\'https://doi.org/10.1007/978-3-030-13969-8_4\'</br>}","url":"https://arxiv.org/pdf/2010.16074.pdf"},"zhou2019hyper":{"title":"Hyper-Pairing Network for Multi-phase Pancreatic Ductal Adenocarcinoma Segmentation","author":"Yuyin Zhou, <b>Yingwei Li</b>, Zhishuai Zhang, Yan Wang, Angtian Wang, Elliot K Fishman, Alan Yuille, Seyoun Park","booktitle":"MICCAI, 2019","image":"/publications/zhou2019hyper.png","year":2019,"tags":["MultiModality"],"bibtex":"@inproceedings{zhou2019hyper,</br>title={Hyper-Pairing Network for Multi-phase Pancreatic Ductal Adenocarcinoma Segmentation},</br>author={Zhou, Yuyin and Li, Yingwei and Zhang, Zhishuai and Wang, Yan and Wang, Angtian and Fishman, Elliot K and Yuille, Alan L and Park, Seyoun},</br>booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},</br>pages={155--163},</br>year={2019},</br>organization={Springer}</br>}","url":"https://arxiv.org/pdf/1909.00906.pdf"},"zhou2019multi":{"title":"Multi-Scale Attentional Network for Multi-Focal Segmentation of Active Bleed after Pelvic Fractures","author":"Yuyin Zhou, David Dreizin, <b>Yingwei Li</b>, Zhishuai Zhang, Yan Wang, Alan Yuille","booktitle":"MICCAI-MLMI, 2019","image":"/publications/zhou2019multi.png","year":2019,"bibtex":"@InProceedings{10.1007/978-3-030-32692-0_53,</br>author=\'Zhou, Yuyin and Dreizin, David and Li, Yingwei and Zhang, Zhishuai and Wang, Yan and Yuille, Alan\',</br>title=\'Multi-scale Attentional Network for Multi-focal Segmentation of Active Bleed After Pelvic Fractures\',</br>booktitle=\'Machine Learning in Medical Imaging\',</br>year=\'2019\',</br>publisher=\'Springer International Publishing\',</br>address=\'Cham\',</br>pages=\'461--469\',</br>isbn=\'978-3-030-32692-0\'</br>}","url":"https://arxiv.org/pdf/1906.09540.pdf"}}')},11:function(i,n,e){var a=e(10),t=e(18),r=e(14),o=e(22),u=e(31),l=function(i,n,e){var s,g,h,c,b=i&l.F,p=i&l.G,d=i&l.S,f=i&l.P,m=i&l.B,y=p?a:d?a[n]||(a[n]={}):(a[n]||{}).prototype,v=p?t:t[n]||(t[n]={}),Y=v.prototype||(v.prototype={});for(s in p&&(e=n),e)h=((g=!b&&y&&void 0!==y[s])?y:e)[s],c=m&&g?u(h,a):f&&"function"==typeof h?u(Function.call,h):h,y&&o(y,s,h,i&l.U),v[s]!=h&&r(v,s,c),f&&Y[s]!=h&&(Y[s]=h)};a.core=t,l.F=1,l.G=2,l.S=4,l.P=8,l.B=16,l.W=32,l.U=64,l.R=128,i.exports=l},13:function(i,n){i.exports=function(i){try{return!!i()}catch(i){return!0}}},14:function(i,n,e){var a=e(21),t=e(29);i.exports=e(16)?function(i,n,e){return a.f(i,n,t(1,e))}:function(i,n,e){return i[n]=e,i}},15:function(i,n){i.exports=function(i){return"object"==typeof i?null!==i:"function"==typeof i}},16:function(i,n,e){i.exports=!e(13)((function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a}))},17:function(i,n,e){var a=e(15);i.exports=function(i){if(!a(i))throw TypeError(i+" is not an object!");return i}},18:function(i,n){var e=i.exports={version:"2.6.11"};"number"==typeof __e&&(__e=e)},19:function(i,n){i.exports=function(i){if(null==i)throw TypeError("Can't call method on  "+i);return i}},20:function(i,n){var e={}.hasOwnProperty;i.exports=function(i,n){return e.call(i,n)}},21:function(i,n,e){var a=e(17),t=e(41),r=e(42),o=Object.defineProperty;n.f=e(16)?Object.defineProperty:function(i,n,e){if(a(i),n=r(n,!0),a(e),t)try{return o(i,n,e)}catch(i){}if("get"in e||"set"in e)throw TypeError("Accessors not supported!");return"value"in e&&(i[n]=e.value),i}},22:function(i,n,e){var a=e(10),t=e(14),r=e(20),o=e(25)("src"),u=e(51),l=(""+u).split("toString");e(18).inspectSource=function(i){return u.call(i)},(i.exports=function(i,n,e,u){var s="function"==typeof e;s&&(r(e,"name")||t(e,"name",n)),i[n]!==e&&(s&&(r(e,o)||t(e,o,i[n]?""+i[n]:l.join(String(n)))),i===a?i[n]=e:u?i[n]?i[n]=e:t(i,n,e):(delete i[n],t(i,n,e)))})(Function.prototype,"toString",(function(){return"function"==typeof this&&this[o]||u.call(this)}))},221:function(i,n,e){"use strict";var a=e(11),t=e(38),r=e(26),o=e(13),u=[].sort,l=[1,2,3];a(a.P+a.F*(o((function(){l.sort(void 0)}))||!o((function(){l.sort(null)}))||!e(23)(u)),"Array",{sort:function(i){return void 0===i?u.call(r(this)):u.call(r(this),t(i))}})},23:function(i,n,e){"use strict";var a=e(13);i.exports=function(i,n){return!!i&&a((function(){n?i.call(null,(function(){}),1):i.call(null)}))}},24:function(i,n,e){var a=e(18),t=e(10),r=t["__core-js_shared__"]||(t["__core-js_shared__"]={});(i.exports=function(i,n){return r[i]||(r[i]=void 0!==n?n:{})})("versions",[]).push({version:a.version,mode:e(34)?"pure":"global",copyright:"Â© 2019 Denis Pushkarev (zloirock.ru)"})},240:function(i,n,e){"use strict";e.r(n);e(221);var a=e(106),t={props:["frontmatter"],computed:{data:function(){var i=[];for(var n in a)""!==n&&i.push(a[n].year);for(var e=[(i=i.sort())[i.length-1]],t=i.length-2;t>-1;t--)i[t]!==i[t+1]&&e.push(i[t]);return e}}},r=e(0),o=Object(r.a)(t,(function(){var i=this.$createElement,n=this._self._c||i;return n("ContentSlotsDistributor",{attrs:{"slot-key":this.$parent.slotKey}},[n("TagPapers",{attrs:{frontmatter:this.$page.frontmatter}}),this._v(" "),n("papers",{attrs:{highlight:this.$page.frontmatter.highlight,years:this.data}})],1)}),[],!1,null,null,null);n.default=o.exports},25:function(i,n){var e=0,a=Math.random();i.exports=function(i){return"Symbol(".concat(void 0===i?"":i,")_",(++e+a).toString(36))}},26:function(i,n,e){var a=e(19);i.exports=function(i){return Object(a(i))}},29:function(i,n){i.exports=function(i,n){return{enumerable:!(1&i),configurable:!(2&i),writable:!(4&i),value:n}}},31:function(i,n,e){var a=e(38);i.exports=function(i,n,e){if(a(i),void 0===n)return i;switch(e){case 1:return function(e){return i.call(n,e)};case 2:return function(e,a){return i.call(n,e,a)};case 3:return function(e,a,t){return i.call(n,e,a,t)}}return function(){return i.apply(n,arguments)}}},34:function(i,n){i.exports=!1},35:function(i,n,e){var a=e(15),t=e(10).document,r=a(t)&&a(t.createElement);i.exports=function(i){return r?t.createElement(i):{}}},38:function(i,n){i.exports=function(i){if("function"!=typeof i)throw TypeError(i+" is not a function!");return i}},41:function(i,n,e){i.exports=!e(16)&&!e(13)((function(){return 7!=Object.defineProperty(e(35)("div"),"a",{get:function(){return 7}}).a}))},42:function(i,n,e){var a=e(15);i.exports=function(i,n){if(!a(i))return i;var e,t;if(n&&"function"==typeof(e=i.toString)&&!a(t=e.call(i)))return t;if("function"==typeof(e=i.valueOf)&&!a(t=e.call(i)))return t;if(!n&&"function"==typeof(e=i.toString)&&!a(t=e.call(i)))return t;throw TypeError("Can't convert object to primitive value")}},51:function(i,n,e){i.exports=e(24)("native-function-to-string",Function.toString)}}]);